# Simulador MLP XOR 2‚Äì2‚Äì1

Este proyecto implementa un perceptr√≥n multicapa (MLP) de arquitectura 2‚Äì2‚Äì1 para resolver el problema XOR. Incluye una interfaz gr√°fica did√°ctica construida con Tkinter que permite visualizar los pesos, activaciones y salidas del modelo en tiempo real, as√≠ como generar reportes en formato Markdown y gr√°ficos de la curva de p√©rdida.

## ‚ú® Caracter√≠sticas principales

- üé® **Visualizaci√≥n interactiva**: Grafo animado que muestra la red neuronal con colores que indican activaciones y pesos
- üìä **Entrenamiento en tiempo real**: Barra de progreso y m√©tricas actualizadas durante el entrenamiento
- üìà **Exportaci√≥n de resultados**: Genera trazas detalladas, gr√°ficos de p√©rdida y tablas de predicciones
- üéì **Enfoque did√°ctico**: C√≥digo expl√≠cito sin dependencias de NumPy para m√°xima claridad educativa
- ‚ö° **Interfaz responsive**: Entrenamiento en segundo plano para mantener la UI fluida

## üìÅ Contenido del repositorio

\`\`\`
‚îú‚îÄ‚îÄ core/              # Implementaci√≥n del MLP y funciones auxiliares
‚îÇ   ‚îú‚îÄ‚îÄ model.py       # Clase `MLP221` con forward, backward y step
‚îÇ   ‚îú‚îÄ‚îÄ activations.py # Funciones de activaci√≥n (sigmoide)
‚îÇ   ‚îî‚îÄ‚îÄ losses.py      # Funci√≥n de p√©rdida BCE
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ xor.py         # Conjunto de entrenamiento XOR
‚îú‚îÄ‚îÄ trainer/
‚îÇ   ‚îî‚îÄ‚îÄ train.py       # Bucles de entrenamiento (est√°ndar y con callback)
‚îú‚îÄ‚îÄ mlpio/
‚îÇ   ‚îú‚îÄ‚îÄ tracer.py      # Generaci√≥n de bit√°coras Markdown
‚îÇ   ‚îî‚îÄ‚îÄ export.py      # Exportaci√≥n de gr√°fica de p√©rdida y tabla de predicciones
‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îî‚îÄ‚îÄ app.py         # Aplicaci√≥n Tkinter interactiva
‚îú‚îÄ‚îÄ run.py             # Punto de entrada para lanzar la interfaz
‚îî‚îÄ‚îÄ requirements.txt   # Dependencias de Python
\`\`\`

## üöÄ Inicio r√°pido

### Requisitos previos

1. **Python 3.9+** (probado con Python 3.10 y 3.11)
2. Instalar las dependencias:

   \`\`\`bash
   pip install -r requirements.txt
   \`\`\`

   > **Nota**: `matplotlib` se usa √∫nicamente para exportar la curva de p√©rdida (`loss.png`). La interfaz Tkinter forma parte de la biblioteca est√°ndar de Python.

### Ejecutar el simulador

Desde la ra√≠z del repositorio:

\`\`\`bash
python run.py
\`\`\`

Se abrir√° una ventana titulada **"MLP XOR 2‚Äì2‚Äì1 ‚Äî Simulador Did√°ctico"**.

### Opciones de l√≠nea de comandos

\`\`\`bash
# Entrenar 5000 √©pocas antes de abrir la GUI
python run.py --train 5000

# Ajustar learning rate
python run.py --train 3000 --lr 0.3

# Exportar sin abrir GUI
python run.py --export --train 3000

# Benchmark con NumPy (opcional)
python run.py --numpy
\`\`\`

## üéÆ Gu√≠a de uso de la interfaz

### Panel de control

#### Botones de entrada XOR
- **x=00, x=01, x=10, x=11**: Ejecuta un forward pass con la entrada correspondiente
- El bot√≥n seleccionado se destaca en naranja
- La visualizaci√≥n actualiza:
  - Neuronas de entrada (amarillo para 1, gris para 0)
  - Neuronas ocultas (intensidad azul seg√∫n activaci√≥n)
  - Neurona de salida (gradiente rojo seg√∫n predicci√≥n)
  - Pesos visualizados con color y grosor proporcional

#### Controles de entrenamiento

- **LR (Learning Rate)**: Tasa de aprendizaje (recomendado: 0.3 - 0.7)
- **√âpocas**: N√∫mero de iteraciones de entrenamiento completo

#### Botones de acci√≥n

1. **Entrenar**
   - Inicia el entrenamiento con los par√°metros especificados
   - Muestra barra de progreso en tiempo real
   - Actualiza m√©tricas: √©poca actual, p√©rdida y precisi√≥n
   - Al finalizar guarda autom√°ticamente:
     - `trazas.md`: Registro detallado paso a paso
     - `loss.png`: Gr√°fico de la curva de p√©rdida
     - `predicciones.md`: Tabla con predicciones finales

2. **Exportar trazas/figuras**
   - Genera los archivos de reporte sin entrenar
   - √ötil para documentar el estado actual del modelo

3. **Reiniciar pesos**
   - Restablece los pesos a sus valores iniciales
   - Limpia el historial de entrenamiento
   - Reinicia la visualizaci√≥n

### Panel de informaci√≥n

Muestra en tiempo real:
- **x**: Vector de entrada actual
- **y**: Etiqueta objetivo
- **z1**: Pre-activaciones de la capa oculta
- **a1**: Activaciones de la capa oculta (post-sigmoid)
- **z2**: Pre-activaci√≥n de la salida
- **≈∑**: Predicci√≥n del modelo
- **Precisi√≥n**: Porcentaje de aciertos en el dataset XOR

### Visualizaci√≥n del grafo

#### Codificaci√≥n de colores

**Neuronas:**
- üü° **Amarillo**: Neuronas de entrada (m√°s intenso cuando valor = 1)
- üîµ **Azul**: Neuronas ocultas (intensidad seg√∫n activaci√≥n)
- üî¥ **Rojo**: Neurona de salida (gradiente seg√∫n predicci√≥n)

**Conexiones (pesos):**
- üîµ **Azul**: Pesos positivos (m√°s oscuro = mayor magnitud)
- üî¥ **Rojo**: Pesos negativos (m√°s oscuro = mayor magnitud)
- **Grosor**: Proporcional al valor absoluto del peso

## üß† Arquitectura del modelo

### Especificaciones t√©cnicas

\`\`\`
Entrada (2) ‚Üí Oculta (2) ‚Üí Salida (1)
             sigmoid      sigmoid
\`\`\`

- **Funci√≥n de activaci√≥n**: Sigmoid en todas las capas
- **Funci√≥n de p√©rdida**: Binary Cross Entropy (BCE)
- **Optimizador**: Gradient Descent (implementaci√≥n manual)
- **Inicializaci√≥n**: Pesos fijos para reproducibilidad

### Pesos iniciales

\`\`\`python
W1 = [[ 4.0,  4.0],   # h1 ‚Üê [x1, x2]
      [-4.0, -4.0]]   # h2 ‚Üê [x1, x2]
b1 = [-2.0, 6.0]

W2 = [[6.0, 6.0]]     # y ‚Üê [h1, h2]
b2 = [-9.0]
\`\`\`

Estos valores est√°n preajustados cerca de una soluci√≥n del problema XOR para facilitar el aprendizaje.

## üìä Archivos generados

### trazas.md
Registro detallado del entrenamiento incluyendo:
- Pesos y sesgos antes de cada actualizaci√≥n
- Activaciones y logits de cada capa
- Gradientes calculados en backward
- Pesos actualizados despu√©s de cada paso
- Tabla de predicciones finales

### loss.png
Gr√°fico matplotlib que muestra:
- Eje X: √âpocas
- Eje Y: P√©rdida promedio (BCE)
- Permite visualizar la convergencia del modelo

### predicciones.md
Tabla markdown con:
- Entradas XOR (x1, x2)
- Etiquetas verdaderas (y)
- Predicciones del modelo (≈∑)

## üéØ Flujo de trabajo recomendado

1. **Exploraci√≥n inicial**
   \`\`\`bash
   python run.py
   \`\`\`
   - Prueba los 4 botones de entrada
   - Observa las activaciones con pesos iniciales

2. **Primer entrenamiento**
   - Configura LR=0.5, √âpocas=3000
   - Presiona "Entrenar"
   - Observa c√≥mo cambian colores y grosores

3. **An√°lisis de resultados**
   - Revisa `loss.png` para ver la convergencia
   - Examina `trazas.md` para entender el proceso
   - Verifica `predicciones.md` para la precisi√≥n final

4. **Experimentaci√≥n**
   - Prueba diferentes learning rates (0.1, 0.5, 1.0)
   - Var√≠a el n√∫mero de √©pocas
   - Usa "Reiniciar pesos" para comparar experimentos

## üõ†Ô∏è Soluci√≥n de problemas

### Tkinter no abre en Linux
\`\`\`bash
sudo apt-get install python3-tk
\`\`\`

### Entrenamiento lento
- Reduce el n√∫mero de √©pocas para pruebas r√°pidas
- La actualizaci√≥n visual cada 10% del progreso mantiene la UI responsive

### Los pesos no convergen
- Aumenta el n√∫mero de √©pocas (prueba 5000-10000)
- Ajusta el learning rate (prueba valores entre 0.3 y 0.7)
- Verifica que los pesos iniciales no est√©n muy alejados

### Limpiar archivos generados
\`\`\`bash
rm trazas.md loss.png predicciones.md
\`\`\`

## üß™ Modo exportaci√≥n (sin GUI)

Para generar reportes directamente:

\`\`\`bash
python run.py --export --train 3000 --lr 0.5
\`\`\`

√ötil para:
- Integraci√≥n en pipelines automatizados
- Generaci√≥n de reportes batch
- Servidores sin display

## üî¨ Detalles de implementaci√≥n

### ¬øPor qu√© listas en vez de NumPy?

Este proyecto usa listas de Python y bucles expl√≠citos para:
- **Claridad educativa**: Cada operaci√≥n es expl√≠cita y f√°cil de seguir
- **Entendimiento profundo**: Los estudiantes ven exactamente qu√© hace cada l√≠nea
- **Sin abstracciones**: No hay "magia" detr√°s de operaciones vectorizadas

### Estabilidad num√©rica

- **Sigmoid**: Implementaci√≥n dual para evitar overflow
- **BCE**: Clipping con epsilon para prevenir log(0)
- **Gradientes**: Uso de derivada simplificada para BCE+Sigmoid

### Threading para UI responsive

El entrenamiento se ejecuta en un thread separado:
- Callback peri√≥dico actualiza la UI
- Progreso visible en tiempo real
- Botones deshabilitados durante entrenamiento
- Manejo robusto de errores

## üìö Recursos adicionales

### Para estudiantes

- El c√≥digo est√° extensamente comentado en espa√±ol
- Cada funci√≥n tiene docstrings explicativos
- Los nombres de variables son descriptivos
- La estructura del proyecto es modular y f√°cil de navegar

### Para instructores

- Ideal para clases de Machine Learning introductorio
- Los estudiantes pueden modificar f√°cilmente:
  - Funciones de activaci√≥n (`core/activations.py`)
  - Funciones de p√©rdida (`core/losses.py`)
  - Arquitectura de la red (`core/model.py`)
- Las trazas detalladas facilitan debugging conceptual

## ü§ù Contribuciones

Este es un proyecto educativo. Las contribuciones son bienvenidas, especialmente:
- Mejoras en la documentaci√≥n
- Nuevas visualizaciones
- Funciones de activaci√≥n/p√©rdida adicionales
- Tests automatizados
- Traducciones a otros idiomas

## üìÑ Licencia

Este proyecto est√° dise√±ado con fines educativos. Si√©ntete libre de usar, modificar y distribuir el c√≥digo.

---

**¬°Disfruta explorando c√≥mo aprende un MLP a resolver el XOR con una interfaz visual e interactiva!** üéâ
